{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deep Hedging sous Black-Scholes avec Sauts de Merton\n",
                "\n",
                "## Introduction\n",
                "\n",
                "Ce notebook implémente une stratégie de **Deep Hedging** pour une option européenne dans un monde de type **Black-Scholes** avec possibilité de **sauts de Merton**.\n",
                "\n",
                "### Objectifs\n",
                "\n",
                "1. Comparer une stratégie de couverture classique (Delta Hedging) à une stratégie apprise via réseaux de neurones\n",
                "2. Optimiser la couverture en minimisant le risque de queue (CVaR)\n",
                "3. Gérer les frictions de marché (coûts de transaction, rebalancement discret)\n",
                "\n",
                "### Architecture\n",
                "\n",
                "- **Simulateur**: Trajectoires Black-Scholes ou Merton\n",
                "- **Modèle neuronal**: MLP ou LSTM générant des ratios de couverture\n",
                "- **Fonction de perte**: CVaR (Conditional Value-at-Risk)\n",
                "- **Comparaison**: Delta Hedging analytique vs Deep Hedging"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration et Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torch.nn.functional as F\n",
                "import matplotlib.pyplot as plt\n",
                "from dataclasses import dataclass\n",
                "from typing import Dict, Tuple, Optional\n",
                "\n",
                "# Configuration du device\n",
                "DTYPE = torch.float32\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    DEVICE = torch.device(\"cuda\")\n",
                "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
                "    DEVICE = torch.device(\"mps\")\n",
                "else:\n",
                "    DEVICE = torch.device(\"cpu\")\n",
                "\n",
                "print(f\"Device: {DEVICE}, dtype: {DTYPE}\")\n",
                "\n",
                "# Style des graphiques\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration des Paramètres\n",
                "\n",
                "Définition des paramètres de marché, de training et globaux via `dataclasses`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class MarketConfig:\n",
                "    \"\"\"Configuration des paramètres de marché.\"\"\"\n",
                "    # Black-Scholes\n",
                "    S0: float = 100.0          # Prix initial\n",
                "    r: float = 0.03            # Taux sans risque\n",
                "    q: float = 0.0             # Dividende\n",
                "    sigma: float = 0.2         # Volatilité\n",
                "    T: float = 1.0             # Maturité\n",
                "    n_steps: int = 52          # Nombre de steps de hedging\n",
                "    \n",
                "    # Option\n",
                "    K: float = 100.0           # Strike\n",
                "    is_call: bool = True       # Call ou Put\n",
                "    \n",
                "    # Merton Jump-Diffusion\n",
                "    use_jumps: bool = False    # Activer les sauts\n",
                "    lambda_jump: float = 1.0   # Intensité de Poisson\n",
                "    mu_J: float = -0.1         # Moyenne du log-jump\n",
                "    sigma_J: float = 0.3       # Std du log-jump\n",
                "    \n",
                "    # Frictions\n",
                "    cost_s: float = 0.0002     # Coûts de transaction\n",
                "    \n",
                "    # Données\n",
                "    n_paths_train: int = 200_000\n",
                "    n_paths_val: int = 50_000\n",
                "    \n",
                "    def __post_init__(self):\n",
                "        \"\"\"Validation des paramètres.\"\"\"\n",
                "        assert self.T > 0, \"T must be positive\"\n",
                "        assert self.sigma > 0, \"sigma must be positive\"\n",
                "        assert self.S0 > 0, \"S0 must be positive\"\n",
                "        assert self.K > 0, \"K must be positive\"\n",
                "        assert self.n_steps > 0, \"n_steps must be positive\"\n",
                "\n",
                "@dataclass\n",
                "class TrainingConfig:\n",
                "    \"\"\"Configuration du training.\"\"\"\n",
                "    n_epochs: int = 50\n",
                "    batch_size: int = 10_000\n",
                "    lr: float = 1e-3\n",
                "    cvar_alpha: float = 0.025   # Niveau de CVaR\n",
                "    print_every: int = 5\n",
                "    \n",
                "    def __post_init__(self):\n",
                "        assert 0 < self.cvar_alpha < 1, \"cvar_alpha must be in (0,1)\"\n",
                "\n",
                "@dataclass\n",
                "class DeepHedgingConfig:\n",
                "    \"\"\"Configuration globale.\"\"\"\n",
                "    market: MarketConfig = MarketConfig()\n",
                "    training: TrainingConfig = TrainingConfig()\n",
                "    device: torch.device = DEVICE\n",
                "    dtype: torch.dtype = DTYPE\n",
                "    seed: int = 42\n",
                "\n",
                "# Instance globale\n",
                "cfg = DeepHedgingConfig()\n",
                "print(f\"Configuration créée: {cfg.market.n_steps} steps, CVaR α={cfg.training.cvar_alpha}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Simulation des Prix (Black-Scholes et Merton)\n",
                "\n",
                "Implémentation des simulateurs de trajectoires avec **vectorisation optimale**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BlackScholesWorld:\n",
                "    \"\"\"Simulateur Black-Scholes optimisé.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: MarketConfig):\n",
                "        self.cfg = config\n",
                "        self.dt = config.T / config.n_steps\n",
                "        self.t_grid = np.linspace(0, config.T, config.n_steps + 1)\n",
                "        \n",
                "    def simulate_paths(self, n_paths: int, seed: int = 42) -> Dict[str, np.ndarray]:\n",
                "        \"\"\"\n",
                "        Simule des trajectoires BS (version vectorisée optimale).\n",
                "        \n",
                "        Returns:\n",
                "            dict avec 'S', 'dS', 'payoff', 't_grid'\n",
                "        \"\"\"\n",
                "        rng = np.random.default_rng(seed)\n",
                "        m = self.cfg\n",
                "        \n",
                "        # Bruits gaussiens\n",
                "        Z = rng.standard_normal((n_paths, m.n_steps)).astype(np.float32)\n",
                "        \n",
                "        # Drift et diffusion\n",
                "        drift = (m.r - m.q - 0.5 * m.sigma**2) * self.dt\n",
                "        vol = m.sigma * np.sqrt(self.dt)\n",
                "        \n",
                "        # Simulation vectorisée complète\n",
                "        log_returns = drift + vol * Z\n",
                "        log_S = np.cumsum(log_returns, axis=1)\n",
                "        \n",
                "        S = np.zeros((n_paths, m.n_steps + 1), dtype=np.float32)\n",
                "        S[:, 0] = m.S0\n",
                "        S[:, 1:] = m.S0 * np.exp(log_S)\n",
                "        \n",
                "        # Incréments\n",
                "        dS = np.diff(S, axis=1)\n",
                "        \n",
                "        # Payoff\n",
                "        if m.is_call:\n",
                "            payoff = np.maximum(S[:, -1] - m.K, 0.0)\n",
                "        else:\n",
                "            payoff = np.maximum(m.K - S[:, -1], 0.0)\n",
                "        \n",
                "        return {\n",
                "            'S': S,\n",
                "            'dS': dS,\n",
                "            'payoff': payoff,\n",
                "            't_grid': self.t_grid\n",
                "        }\n",
                "\n",
                "class MertonWorld(BlackScholesWorld):\n",
                "    \"\"\"Simulateur Merton Jump-Diffusion.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: MarketConfig):\n",
                "        super().__init__(config)\n",
                "        # Correction du drift pour risque neutre\n",
                "        self.kappa = np.exp(config.mu_J + 0.5 * config.sigma_J**2) - 1.0\n",
                "        \n",
                "    def simulate_paths(self, n_paths: int, seed: int = 42) -> Dict[str, np.ndarray]:\n",
                "        \"\"\"Simule des trajectoires Merton avec sauts.\"\"\"\n",
                "        rng = np.random.default_rng(seed)\n",
                "        m = self.cfg\n",
                "        \n",
                "        S = np.zeros((n_paths, m.n_steps + 1), dtype=np.float64)\n",
                "        S[:, 0] = m.S0\n",
                "        \n",
                "        drift = (m.r - m.q - m.lambda_jump * self.kappa - 0.5 * m.sigma**2) * self.dt\n",
                "        vol = m.sigma * np.sqrt(self.dt)\n",
                "        \n",
                "        for t in range(m.n_steps):\n",
                "            # Diffusion\n",
                "            Z = rng.standard_normal(n_paths)\n",
                "            \n",
                "            # Sauts\n",
                "            N_jump = rng.poisson(m.lambda_jump * self.dt, n_paths)\n",
                "            log_jump = np.zeros(n_paths, dtype=np.float64)\n",
                "            \n",
                "            has_jump = N_jump > 0\n",
                "            if np.any(has_jump):\n",
                "                n_total_jumps = N_jump[has_jump].sum()\n",
                "                Y = rng.normal(m.mu_J, m.sigma_J, n_total_jumps)\n",
                "                \n",
                "                idx = np.concatenate([[0], np.cumsum(N_jump[has_jump])])\n",
                "                for k in range(len(idx) - 1):\n",
                "                    log_jump[np.where(has_jump)[0][k]] = Y[idx[k]:idx[k+1]].sum()\n",
                "            \n",
                "            # Mise à jour\n",
                "            dlog_S = drift + vol * Z + log_jump\n",
                "            S[:, t+1] = S[:, t] * np.exp(dlog_S)\n",
                "        \n",
                "        dS = np.diff(S, axis=1)\n",
                "        \n",
                "        if m.is_call:\n",
                "            payoff = np.maximum(S[:, -1] - m.K, 0.0)\n",
                "        else:\n",
                "            payoff = np.maximum(m.K - S[:, -1], 0.0)\n",
                "        \n",
                "        return {\n",
                "            'S': S.astype(np.float32),\n",
                "            'dS': dS.astype(np.float32),\n",
                "            'payoff': payoff.astype(np.float32),\n",
                "            't_grid': self.t_grid\n",
                "        }\n",
                "\n",
                "# Test rapide\n",
                "world = BlackScholesWorld(cfg.market)\n",
                "test_data = world.simulate_paths(1000, seed=42)\n",
                "print(f\"Shapes: S={test_data['S'].shape}, dS={test_data['dS'].shape}, payoff={test_data['payoff'].shape}\")\n",
                "print(f\"Prix moyen final: {test_data['S'][:, -1].mean():.2f}\")\n",
                "print(f\"Payoff moyen: {test_data['payoff'].mean():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Modèle Neuronal de Couverture\n",
                "\n",
                "Architecture MLP générant les ratios de hedging à partir de l'état du marché."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class HedgingNetwork(nn.Module):\n",
                "    \"\"\"Réseau de neurones pour la stratégie de hedging.\"\"\"\n",
                "    \n",
                "    def __init__(self, hidden_sizes=[64, 64], activation='relu'):\n",
                "        super().__init__()\n",
                "        self.hidden_sizes = hidden_sizes\n",
                "        \n",
                "        # Input: [S_normalized, time_to_maturity]\n",
                "        layers = []\n",
                "        in_dim = 2\n",
                "        \n",
                "        for h_dim in hidden_sizes:\n",
                "            layers.append(nn.Linear(in_dim, h_dim))\n",
                "            if activation == 'relu':\n",
                "                layers.append(nn.ReLU())\n",
                "            elif activation == 'tanh':\n",
                "                layers.append(nn.Tanh())\n",
                "            in_dim = h_dim\n",
                "        \n",
                "        # Output: hedge ratio\n",
                "        layers.append(nn.Linear(in_dim, 1))\n",
                "        \n",
                "        self.network = nn.Sequential(*layers)\n",
                "        \n",
                "    def forward(self, S, t, S0, T):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            S: Prix du sous-jacent (batch_size,)\n",
                "            t: Temps actuel (batch_size,)\n",
                "            S0: Prix initial pour normalisation\n",
                "            T: Maturité pour normalisation\n",
                "        \n",
                "        Returns:\n",
                "            Hedge ratio (batch_size,)\n",
                "        \"\"\"\n",
                "        S_norm = S / S0\n",
                "        tau = 1.0 - t / T  # Time to maturity\n",
                "        \n",
                "        x = torch.stack([S_norm, tau], dim=-1)\n",
                "        hedge_ratio = self.network(x).squeeze(-1)\n",
                "        \n",
                "        return hedge_ratio\n",
                "\n",
                "# Test du modèle\n",
                "model = HedgingNetwork(hidden_sizes=[32, 32]).to(DEVICE)\n",
                "print(f\"Modèle créé: {sum(p.numel() for p in model.parameters())} paramètres\")\n",
                "\n",
                "# Test forward pass\n",
                "S_test = torch.tensor([100.0, 105.0, 95.0], device=DEVICE)\n",
                "t_test = torch.tensor([0.0, 0.5, 1.0], device=DEVICE)\n",
                "ratios = model(S_test, t_test, cfg.market.S0, cfg.market.T)\n",
                "print(f\"Hedge ratios de test: {ratios}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Fonction de Perte CVaR\n",
                "\n",
                "Implémentation de la Conditional Value-at-Risk pour optimiser le risque de queue."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CVaRLoss(nn.Module):\n",
                "    \"\"\"Fonction de perte CVaR (Rockafellar & Uryasev).\"\"\"\n",
                "    \n",
                "    def __init__(self, alpha=0.025):\n",
                "        super().__init__()\n",
                "        self.alpha = alpha\n",
                "        \n",
                "    def forward(self, pnl):\n",
                "        \"\"\"\n",
                "        Calcule le CVaR du PnL.\n",
                "        \n",
                "        Args:\n",
                "            pnl: Profit & Loss (batch_size,)\n",
                "        \n",
                "        Returns:\n",
                "            CVaR (scalaire)\n",
                "        \"\"\"\n",
                "        # On minimise -PnL, donc on cherche le CVaR des pertes\n",
                "        losses = -pnl\n",
                "        \n",
                "        # VaR: quantile à alpha\n",
                "        var = torch.quantile(losses, self.alpha)\n",
                "        \n",
                "        # CVaR: moyenne des pertes au-delà du VaR\n",
                "        excess_losses = torch.relu(losses - var)\n",
                "        cvar = var + excess_losses.mean() / self.alpha\n",
                "        \n",
                "        return cvar\n",
                "\n",
                "# Test de la loss\n",
                "cvar_loss = CVaRLoss(alpha=0.025)\n",
                "pnl_test = torch.randn(1000) * 10  # PnL simulé\n",
                "loss_val = cvar_loss(pnl_test)\n",
                "print(f\"CVaR test: {loss_val:.4f}\")\n",
                "print(f\"Moyenne PnL: {pnl_test.mean():.4f}, Std: {pnl_test.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Environnement de Hedging\n",
                "\n",
                "Calcul du PnL avec coûts de transaction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class HedgingEnv:\n",
                "    \"\"\"Environnement pour calculer le PnL de la stratégie.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: MarketConfig, model: nn.Module, device=DEVICE):\n",
                "        self.cfg = config\n",
                "        self.model = model\n",
                "        self.device = device\n",
                "        self.dt = config.T / config.n_steps\n",
                "        \n",
                "    def compute_pnl(self, data: Dict[str, np.ndarray]) -> torch.Tensor:\n",
                "        \"\"\"\n",
                "        Calcule le PnL de la stratégie de hedging.\n",
                "        \n",
                "        Args:\n",
                "            data: dict avec 'S', 'dS', 'payoff'\n",
                "        \n",
                "        Returns:\n",
                "            PnL (n_paths,)\n",
                "        \"\"\"\n",
                "        S = torch.tensor(data['S'], device=self.device, dtype=DTYPE)\n",
                "        dS = torch.tensor(data['dS'], device=self.device, dtype=DTYPE)\n",
                "        payoff = torch.tensor(data['payoff'], device=self.device, dtype=DTYPE)\n",
                "        \n",
                "        n_paths = S.shape[0]\n",
                "        pnl = -payoff  # On part du payoff négatif (on est vendeur)\n",
                "        \n",
                "        hedge_prev = torch.zeros(n_paths, device=self.device)\n",
                "        \n",
                "        for t in range(self.cfg.n_steps):\n",
                "            # État actuel\n",
                "            S_t = S[:, t]\n",
                "            t_val = torch.full((n_paths,), t * self.dt, device=self.device)\n",
                "            \n",
                "            # Ratio de hedging via le modèle\n",
                "            hedge_t = self.model(S_t, t_val, self.cfg.S0, self.cfg.T)\n",
                "            \n",
                "            # PnL du hedge\n",
                "            pnl += hedge_prev * dS[:, t]\n",
                "            \n",
                "            # Coûts de transaction\n",
                "            trade_amount = torch.abs(hedge_t - hedge_prev)\n",
                "            transaction_cost = self.cfg.cost_s * trade_amount * S_t\n",
                "            pnl -= transaction_cost\n",
                "            \n",
                "            hedge_prev = hedge_t\n",
                "        \n",
                "        # Liquidation finale\n",
                "        S_T = S[:, -1]\n",
                "        pnl += hedge_prev * (S_T - S[:, -2])\n",
                "        pnl -= self.cfg.cost_s * torch.abs(hedge_prev) * S_T\n",
                "        \n",
                "        return pnl\n",
                "\n",
                "# Test de l'environnement\n",
                "env = HedgingEnv(cfg.market, model, DEVICE)\n",
                "test_pnl = env.compute_pnl(test_data)\n",
                "print(f\"PnL test: mean={test_pnl.mean():.4f}, std={test_pnl.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training Loop\n",
                "\n",
                "Entraînement du modèle avec optimisation CVaR."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DeepHedgingTrainer:\n",
                "    \"\"\"Gestionnaire de training pour Deep Hedging.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: DeepHedgingConfig, model: nn.Module, env: HedgingEnv):\n",
                "        self.config = config\n",
                "        self.model = model\n",
                "        self.env = env\n",
                "        self.optimizer = optim.Adam(model.parameters(), lr=config.training.lr)\n",
                "        self.loss_fn = CVaRLoss(alpha=config.training.cvar_alpha)\n",
                "        self.history = {'train_loss': [], 'val_loss': []}\n",
                "        \n",
                "    def train_epoch(self, data: Dict[str, np.ndarray]) -> float:\n",
                "        \"\"\"Entraîne le modèle sur une epoch.\"\"\"\n",
                "        self.model.train()\n",
                "        self.optimizer.zero_grad()\n",
                "        \n",
                "        # Forward pass\n",
                "        pnl = self.env.compute_pnl(data)\n",
                "        \n",
                "        # Loss\n",
                "        loss = self.loss_fn(pnl)\n",
                "        \n",
                "        # Backward\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
                "        self.optimizer.step()\n",
                "        \n",
                "        return loss.item()\n",
                "    \n",
                "    def validate(self, data: Dict[str, np.ndarray]) -> Tuple[float, Dict]:\n",
                "        \"\"\"Évalue le modèle sur les données de validation.\"\"\"\n",
                "        self.model.eval()\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            pnl = self.env.compute_pnl(data)\n",
                "            loss = self.loss_fn(pnl)\n",
                "            \n",
                "            metrics = {\n",
                "                'mean_pnl': pnl.mean().item(),\n",
                "                'std_pnl': pnl.std().item(),\n",
                "                'cvar': loss.item(),\n",
                "                'var': torch.quantile(-pnl, self.config.training.cvar_alpha).item()\n",
                "            }\n",
                "        \n",
                "        return loss.item(), metrics\n",
                "    \n",
                "    def train(self, world):\n",
                "        \"\"\"Boucle de training complète.\"\"\"\n",
                "        print(\"\\n\" + \"=\"*70)\n",
                "        print(\"DÉMARRAGE DU TRAINING\")\n",
                "        print(\"=\"*70)\n",
                "        \n",
                "        # Génération des données\n",
                "        print(\"Génération des données...\")\n",
                "        train_data = world.simulate_paths(self.config.market.n_paths_train, seed=self.config.seed)\n",
                "        val_data = world.simulate_paths(self.config.market.n_paths_val, seed=self.config.seed + 1)\n",
                "        print(f\"Train: {train_data['S'].shape[0]} paths, Val: {val_data['S'].shape[0]} paths\")\n",
                "        \n",
                "        # Training loop\n",
                "        for epoch in range(1, self.config.training.n_epochs + 1):\n",
                "            train_loss = self.train_epoch(train_data)\n",
                "            self.history['train_loss'].append(train_loss)\n",
                "            \n",
                "            if epoch % self.config.training.print_every == 0:\n",
                "                val_loss, metrics = self.validate(val_data)\n",
                "                self.history['val_loss'].append(val_loss)\n",
                "                \n",
                "                print(f\"\\nEpoch {epoch}/{self.config.training.n_epochs}\")\n",
                "                print(f\"  Train Loss: {train_loss:.6f}\")\n",
                "                print(f\"  Val Loss:   {val_loss:.6f}\")\n",
                "                print(f\"  PnL: μ={metrics['mean_pnl']:.4f}, σ={metrics['std_pnl']:.4f}\")\n",
                "                print(f\"  CVaR={metrics['cvar']:.4f}, VaR={metrics['var']:.4f}\")\n",
                "        \n",
                "        print(\"\\n\" + \"=\"*70)\n",
                "        print(\"TRAINING TERMINÉ\")\n",
                "        print(\"=\"*70 + \"\\n\")\n",
                "        \n",
                "        return self.history\n",
                "\n",
                "print(\"Trainer créé et prêt pour l'entraînement.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Exécution du Training\n",
                "\n",
                "Entraînement du modèle de Deep Hedging."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Création du monde\n",
                "world_train = BlackScholesWorld(cfg.market)\n",
                "\n",
                "# Création du modèle\n",
                "model = HedgingNetwork(hidden_sizes=[64, 64]).to(DEVICE)\n",
                "\n",
                "# Création de l'environnement\n",
                "env = HedgingEnv(cfg.market, model, DEVICE)\n",
                "\n",
                "# Création du trainer\n",
                "trainer = DeepHedgingTrainer(cfg, model, env)\n",
                "\n",
                "# Training\n",
                "history = trainer.train(world_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Visualisation des Résultats\n",
                "\n",
                "Analyse des performances du modèle entraîné."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Loss curve\n",
                "axes[0].plot(history['train_loss'], label='Train Loss', alpha=0.7)\n",
                "if history['val_loss']:\n",
                "    val_epochs = [i * cfg.training.print_every for i in range(len(history['val_loss']))]\n",
                "    axes[0].plot(val_epochs, history['val_loss'], label='Val Loss', marker='o', linewidth=2)\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('CVaR Loss')\n",
                "axes[0].set_title('Courbe d\\'Apprentissage')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Distribution du PnL\n",
                "model.eval()\n",
                "test_data = world_train.simulate_paths(10_000, seed=999)\n",
                "with torch.no_grad():\n",
                "    test_pnl = env.compute_pnl(test_data).cpu().numpy()\n",
                "\n",
                "axes[1].hist(test_pnl, bins=50, alpha=0.7, edgecolor='black')\n",
                "axes[1].axvline(test_pnl.mean(), color='red', linestyle='--', linewidth=2, label=f'Moyenne: {test_pnl.mean():.3f}')\n",
                "axes[1].axvline(np.percentile(test_pnl, 2.5), color='orange', linestyle='--', linewidth=2, label=f'VaR 2.5%: {np.percentile(test_pnl, 2.5):.3f}')\n",
                "axes[1].set_xlabel('PnL')\n",
                "axes[1].set_ylabel('Fréquence')\n",
                "axes[1].set_title('Distribution du PnL (Test)')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nStatistiques finales:\")\n",
                "print(f\"  PnL moyen: {test_pnl.mean():.4f}\")\n",
                "print(f\"  PnL std:   {test_pnl.std():.4f}\")\n",
                "print(f\"  VaR 2.5%:  {np.percentile(test_pnl, 2.5):.4f}\")\n",
                "print(f\"  CVaR 2.5%: {test_pnl[test_pnl <= np.percentile(test_pnl, 2.5)].mean():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Comparaison avec Delta Hedging Classique\n",
                "\n",
                "Comparaison de notre stratégie Deep Hedging avec le Delta Hedging théorique."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.stats import norm\n",
                "\n",
                "def black_scholes_delta(S, K, T, r, sigma, t, is_call=True):\n",
                "    \"\"\"Calcule le Delta Black-Scholes.\"\"\"\n",
                "    tau = T - t\n",
                "    if tau <= 0:\n",
                "        return 1.0 if (is_call and S > K) else 0.0\n",
                "    \n",
                "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * tau) / (sigma * np.sqrt(tau))\n",
                "    \n",
                "    if is_call:\n",
                "        return norm.cdf(d1)\n",
                "    else:\n",
                "        return norm.cdf(d1) - 1.0\n",
                "\n",
                "def delta_hedging_pnl(data: Dict[str, np.ndarray], config: MarketConfig) -> np.ndarray:\n",
                "    \"\"\"Calcule le PnL avec Delta Hedging classique.\"\"\"\n",
                "    S = data['S']\n",
                "    dS = data['dS']\n",
                "    payoff = data['payoff']\n",
                "    \n",
                "    n_paths = S.shape[0]\n",
                "    pnl = -payoff\n",
                "    \n",
                "    hedge_prev = np.zeros(n_paths)\n",
                "    dt = config.T / config.n_steps\n",
                "    \n",
                "    for t in range(config.n_steps):\n",
                "        S_t = S[:, t]\n",
                "        t_val = t * dt\n",
                "        \n",
                "        # Delta théorique\n",
                "        hedge_t = black_scholes_delta(S_t, config.K, config.T, config.r, config.sigma, t_val, config.is_call)\n",
                "        \n",
                "        # PnL\n",
                "        pnl += hedge_prev * dS[:, t]\n",
                "        \n",
                "        # Coûts\n",
                "        transaction_cost = config.cost_s * np.abs(hedge_t - hedge_prev) * S_t\n",
                "        pnl -= transaction_cost\n",
                "        \n",
                "        hedge_prev = hedge_t\n",
                "    \n",
                "    # Liquidation\n",
                "    S_T = S[:, -1]\n",
                "    pnl += hedge_prev * (S_T - S[:, -2])\n",
                "    pnl -= config.cost_s * np.abs(hedge_prev) * S_T\n",
                "    \n",
                "    return pnl\n",
                "\n",
                "# Comparaison\n",
                "print(\"\\nComparaison Deep Hedging vs Delta Hedging:\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "test_data_comp = world_train.simulate_paths(50_000, seed=12345)\n",
                "\n",
                "# Deep Hedging\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    pnl_deep = env.compute_pnl(test_data_comp).cpu().numpy()\n",
                "\n",
                "# Delta Hedging\n",
                "pnl_delta = delta_hedging_pnl(test_data_comp, cfg.market)\n",
                "\n",
                "# Statistiques\n",
                "print(f\"\\nDeep Hedging:\")\n",
                "print(f\"  Moyenne:  {pnl_deep.mean():.4f}\")\n",
                "print(f\"  Std:      {pnl_deep.std():.4f}\")\n",
                "print(f\"  VaR 2.5%: {np.percentile(pnl_deep, 2.5):.4f}\")\n",
                "print(f\"  CVaR 2.5%:{pnl_deep[pnl_deep <= np.percentile(pnl_deep, 2.5)].mean():.4f}\")\n",
                "\n",
                "print(f\"\\nDelta Hedging:\")\n",
                "print(f\"  Moyenne:  {pnl_delta.mean():.4f}\")\n",
                "print(f\"  Std:      {pnl_delta.std():.4f}\")\n",
                "print(f\"  VaR 2.5%: {np.percentile(pnl_delta, 2.5):.4f}\")\n",
                "print(f\"  CVaR 2.5%:{pnl_delta[pnl_delta <= np.percentile(pnl_delta, 2.5)].mean():.4f}\")\n",
                "\n",
                "# Visualisation comparative\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.hist(pnl_deep, bins=50, alpha=0.6, label='Deep Hedging', edgecolor='black')\n",
                "plt.hist(pnl_delta, bins=50, alpha=0.6, label='Delta Hedging', edgecolor='black')\n",
                "plt.xlabel('PnL')\n",
                "plt.ylabel('Fréquence')\n",
                "plt.title('Distribution des PnL')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "metrics = ['Moyenne', 'Std', 'VaR 2.5%', 'CVaR 2.5%']\n",
                "deep_vals = [pnl_deep.mean(), pnl_deep.std(), np.percentile(pnl_deep, 2.5), \n",
                "             pnl_deep[pnl_deep <= np.percentile(pnl_deep, 2.5)].mean()]\n",
                "delta_vals = [pnl_delta.mean(), pnl_delta.std(), np.percentile(pnl_delta, 2.5),\n",
                "              pnl_delta[pnl_delta <= np.percentile(pnl_delta, 2.5)].mean()]\n",
                "\n",
                "x = np.arange(len(metrics))\n",
                "width = 0.35\n",
                "plt.bar(x - width/2, deep_vals, width, label='Deep Hedging', alpha=0.8)\n",
                "plt.bar(x + width/2, delta_vals, width, label='Delta Hedging', alpha=0.8)\n",
                "plt.xlabel('Métrique')\n",
                "plt.ylabel('Valeur')\n",
                "plt.title('Comparaison des Métriques')\n",
                "plt.xticks(x, metrics, rotation=15)\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3, axis='y')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Analyse des Stratégies de Hedging\n",
                "\n",
                "Visualisation des ratios de hedging le long d'une trajectoire typique."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulation d'une trajectoire\n",
                "single_path = world_train.simulate_paths(1, seed=777)\n",
                "S_path = single_path['S'][0]\n",
                "t_grid = single_path['t_grid']\n",
                "\n",
                "# Calcul des hedges\n",
                "deep_hedges = []\n",
                "delta_hedges = []\n",
                "\n",
                "model.eval()\n",
                "for t_idx in range(cfg.market.n_steps):\n",
                "    S_t = S_path[t_idx]\n",
                "    t_val = t_grid[t_idx]\n",
                "    \n",
                "    # Deep Hedging\n",
                "    with torch.no_grad():\n",
                "        S_tensor = torch.tensor([S_t], device=DEVICE, dtype=DTYPE)\n",
                "        t_tensor = torch.tensor([t_val], device=DEVICE, dtype=DTYPE)\n",
                "        hedge_deep = model(S_tensor, t_tensor, cfg.market.S0, cfg.market.T).cpu().item()\n",
                "    deep_hedges.append(hedge_deep)\n",
                "    \n",
                "    # Delta Hedging\n",
                "    hedge_delta = black_scholes_delta(S_t, cfg.market.K, cfg.market.T, cfg.market.r, \n",
                "                                      cfg.market.sigma, t_val, cfg.market.is_call)\n",
                "    delta_hedges.append(hedge_delta)\n",
                "\n",
                "# Visualisation\n",
                "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
                "\n",
                "# Prix du sous-jacent\n",
                "axes[0].plot(t_grid, S_path, linewidth=2, color='blue')\n",
                "axes[0].axhline(cfg.market.K, color='red', linestyle='--', linewidth=1.5, label=f'Strike = {cfg.market.K}')\n",
                "axes[0].set_ylabel('Prix du Sous-jacent')\n",
                "axes[0].set_title('Trajectoire du Prix')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Ratios de hedging\n",
                "axes[1].plot(t_grid[:-1], deep_hedges, label='Deep Hedging', linewidth=2, alpha=0.8)\n",
                "axes[1].plot(t_grid[:-1], delta_hedges, label='Delta Hedging', linewidth=2, alpha=0.8, linestyle='--')\n",
                "axes[1].set_xlabel('Temps')\n",
                "axes[1].set_ylabel('Ratio de Hedging')\n",
                "axes[1].set_title('Stratégies de Couverture')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Test avec Sauts de Merton (Optionnel)\n",
                "\n",
                "Entraînement du modèle sur un monde avec sauts pour tester la robustesse."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration avec sauts\n",
                "cfg_merton = DeepHedgingConfig()\n",
                "cfg_merton.market.use_jumps = True\n",
                "cfg_merton.market.lambda_jump = 2.0\n",
                "cfg_merton.market.mu_J = -0.05\n",
                "cfg_merton.market.sigma_J = 0.15\n",
                "cfg_merton.market.n_paths_train = 100_000  # Moins de paths pour aller plus vite\n",
                "cfg_merton.market.n_paths_val = 20_000\n",
                "cfg_merton.training.n_epochs = 30\n",
                "\n",
                "print(\"Configuration Merton:\")\n",
                "print(f\"  λ = {cfg_merton.market.lambda_jump}\")\n",
                "print(f\"  μ_J = {cfg_merton.market.mu_J}\")\n",
                "print(f\"  σ_J = {cfg_merton.market.sigma_J}\")\n",
                "\n",
                "# Création du monde Merton\n",
                "world_merton = MertonWorld(cfg_merton.market)\n",
                "\n",
                "# Nouveau modèle\n",
                "model_merton = HedgingNetwork(hidden_sizes=[64, 64]).to(DEVICE)\n",
                "env_merton = HedgingEnv(cfg_merton.market, model_merton, DEVICE)\n",
                "trainer_merton = DeepHedgingTrainer(cfg_merton, model_merton, env_merton)\n",
                "\n",
                "# Training\n",
                "print(\"\\nTraining sur Merton Jump-Diffusion...\")\n",
                "history_merton = trainer_merton.train(world_merton)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Sauvegarde du Modèle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sauvegarde\n",
                "torch.save({\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'config': cfg,\n",
                "    'history': history\n",
                "}, 'deep_hedging_model.pt')\n",
                "\n",
                "print(\"Modèle sauvegardé dans 'deep_hedging_model.pt'\")\n",
                "\n",
                "# Pour charger:\n",
                "# checkpoint = torch.load('deep_hedging_model.pt')\n",
                "# model.load_state_dict(checkpoint['model_state_dict'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "Ce notebook a implémenté une stratégie de **Deep Hedging** complète:\n",
                "\n",
                "✅ Simulation Black-Scholes et Merton optimisée  \n",
                "✅ Architecture neuronale pour la couverture  \n",
                "✅ Optimisation CVaR du risque de queue  \n",
                "✅ Comparaison avec Delta Hedging classique  \n",
                "✅ Visualisations et analyses détaillées  \n",
                "\n",
                "### Points clés\n",
                "\n",
                "- Le Deep Hedging peut surpasser le Delta Hedging en présence de frictions\n",
                "- L'optimisation CVaR réduit le risque de queue\n",
                "- L'approche est robuste aux sauts (Merton)\n",
                "\n",
                "### Extensions possibles\n",
                "\n",
                "- Tester différentes architectures (LSTM, Attention)\n",
                "- Ajouter des features additionnelles (volatilité implicite, Greeks)\n",
                "- Implémenter d'autres fonctions objectif (Sharpe, Sortino)\n",
                "- Étendre à des options plus complexes (barrières, asiatiques)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}